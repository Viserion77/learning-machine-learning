{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.utils import plot_model\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, LSTM\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.callbacks import EarlyStopping, ReduceLROnPlateau, ModelCheckpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "base = pd.read_csv('/workspaces/learning-machine-learning/udemy/a_z/bolsa_valores/petr4_treinamento.csv')\n",
    "base = base.dropna()\n",
    "base_treinamento = base.iloc[:, 1:7].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "normalizador = MinMaxScaler(feature_range=(0,1))\n",
    "base_treinamento_normalizada = normalizador.fit_transform(base_treinamento)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.76501938],\n",
       "       [0.7562984 ],\n",
       "       [0.78149225],\n",
       "       ...,\n",
       "       [0.57122093],\n",
       "       [0.57655039],\n",
       "       [0.57655039]])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "normalizador_previsao = MinMaxScaler(feature_range=(0,1))\n",
    "normalizador_previsao.fit_transform(base_treinamento[:,0:1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "previsores = []\n",
    "preco_real = []\n",
    "for i in range(90, 1242):\n",
    "    previsores.append(base_treinamento_normalizada[i-90:i, 0:6])\n",
    "    preco_real.append(base_treinamento_normalizada[i, 0])\n",
    "previsores, preco_real = np.array(previsores), np.array(preco_real)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "regressor = Sequential()\n",
    "regressor.add(LSTM(units=100, return_sequences=True, input_shape=(previsores.shape[1], 6)))\n",
    "regressor.add(Dropout(0.3))\n",
    "\n",
    "regressor.add(LSTM(units=50, return_sequences=True))\n",
    "regressor.add(Dropout(0.3))\n",
    "\n",
    "regressor.add(LSTM(units=50, return_sequences=True))\n",
    "regressor.add(Dropout(0.3))\n",
    "\n",
    "regressor.add(LSTM(units=50))\n",
    "regressor.add(Dropout(0.3))\n",
    "\n",
    "regressor.add(Dense(units=1, activation='sigmoid'))\n",
    "\n",
    "regressor.compile(optimizer='adam', loss='mean_squared_error', metrics=['mean_absolute_error'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "es = EarlyStopping(monitor='loss', min_delta=1e-10, patience=10, verbose=1)\n",
    "rlr = ReduceLROnPlateau(monitor='loss', factor=0.2, patience=5, verbose=1)\n",
    "mcp = ModelCheckpoint(filepath='pesos.h5', monitor='loss', save_best_only=True, verbose=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "36/36 [==============================] - ETA: 0s - loss: 0.0180 - mean_absolute_error: 0.1040\n",
      "Epoch 1: loss improved from inf to 0.01799, saving model to pesos.h5\n",
      "36/36 [==============================] - 8s 113ms/step - loss: 0.0180 - mean_absolute_error: 0.1040 - lr: 0.0010\n",
      "Epoch 2/100\n",
      " 1/36 [..............................] - ETA: 3s - loss: 0.0099 - mean_absolute_error: 0.0844"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/python/3.11.5/lib/python3.11/site-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36/36 [==============================] - ETA: 0s - loss: 0.0078 - mean_absolute_error: 0.0699\n",
      "Epoch 2: loss improved from 0.01799 to 0.00783, saving model to pesos.h5\n",
      "36/36 [==============================] - 4s 117ms/step - loss: 0.0078 - mean_absolute_error: 0.0699 - lr: 0.0010\n",
      "Epoch 3/100\n",
      "36/36 [==============================] - ETA: 0s - loss: 0.0059 - mean_absolute_error: 0.0606\n",
      "Epoch 3: loss improved from 0.00783 to 0.00590, saving model to pesos.h5\n",
      "36/36 [==============================] - 4s 116ms/step - loss: 0.0059 - mean_absolute_error: 0.0606 - lr: 0.0010\n",
      "Epoch 4/100\n",
      "36/36 [==============================] - ETA: 0s - loss: 0.0059 - mean_absolute_error: 0.0600\n",
      "Epoch 4: loss improved from 0.00590 to 0.00585, saving model to pesos.h5\n",
      "36/36 [==============================] - 4s 115ms/step - loss: 0.0059 - mean_absolute_error: 0.0600 - lr: 0.0010\n",
      "Epoch 5/100\n",
      "36/36 [==============================] - ETA: 0s - loss: 0.0047 - mean_absolute_error: 0.0528\n",
      "Epoch 5: loss improved from 0.00585 to 0.00466, saving model to pesos.h5\n",
      "36/36 [==============================] - 4s 112ms/step - loss: 0.0047 - mean_absolute_error: 0.0528 - lr: 0.0010\n",
      "Epoch 6/100\n",
      "36/36 [==============================] - ETA: 0s - loss: 0.0044 - mean_absolute_error: 0.0520\n",
      "Epoch 6: loss improved from 0.00466 to 0.00444, saving model to pesos.h5\n",
      "36/36 [==============================] - 4s 110ms/step - loss: 0.0044 - mean_absolute_error: 0.0520 - lr: 0.0010\n",
      "Epoch 7/100\n",
      "36/36 [==============================] - ETA: 0s - loss: 0.0040 - mean_absolute_error: 0.0495\n",
      "Epoch 7: loss improved from 0.00444 to 0.00404, saving model to pesos.h5\n",
      "36/36 [==============================] - 4s 113ms/step - loss: 0.0040 - mean_absolute_error: 0.0495 - lr: 0.0010\n",
      "Epoch 8/100\n",
      "36/36 [==============================] - ETA: 0s - loss: 0.0041 - mean_absolute_error: 0.0492\n",
      "Epoch 8: loss did not improve from 0.00404\n",
      "36/36 [==============================] - 4s 114ms/step - loss: 0.0041 - mean_absolute_error: 0.0492 - lr: 0.0010\n",
      "Epoch 9/100\n",
      "36/36 [==============================] - ETA: 0s - loss: 0.0040 - mean_absolute_error: 0.0486\n",
      "Epoch 9: loss improved from 0.00404 to 0.00401, saving model to pesos.h5\n",
      "36/36 [==============================] - 4s 117ms/step - loss: 0.0040 - mean_absolute_error: 0.0486 - lr: 0.0010\n",
      "Epoch 10/100\n",
      "36/36 [==============================] - ETA: 0s - loss: 0.0037 - mean_absolute_error: 0.0463\n",
      "Epoch 10: loss improved from 0.00401 to 0.00365, saving model to pesos.h5\n",
      "36/36 [==============================] - 4s 116ms/step - loss: 0.0037 - mean_absolute_error: 0.0463 - lr: 0.0010\n",
      "Epoch 11/100\n",
      "36/36 [==============================] - ETA: 0s - loss: 0.0034 - mean_absolute_error: 0.0449\n",
      "Epoch 11: loss improved from 0.00365 to 0.00344, saving model to pesos.h5\n",
      "36/36 [==============================] - 4s 122ms/step - loss: 0.0034 - mean_absolute_error: 0.0449 - lr: 0.0010\n",
      "Epoch 12/100\n",
      "36/36 [==============================] - ETA: 0s - loss: 0.0035 - mean_absolute_error: 0.0459\n",
      "Epoch 12: loss did not improve from 0.00344\n",
      "36/36 [==============================] - 4s 114ms/step - loss: 0.0035 - mean_absolute_error: 0.0459 - lr: 0.0010\n",
      "Epoch 13/100\n",
      "36/36 [==============================] - ETA: 0s - loss: 0.0033 - mean_absolute_error: 0.0442\n",
      "Epoch 13: loss improved from 0.00344 to 0.00325, saving model to pesos.h5\n",
      "36/36 [==============================] - 4s 116ms/step - loss: 0.0033 - mean_absolute_error: 0.0442 - lr: 0.0010\n",
      "Epoch 14/100\n",
      "36/36 [==============================] - ETA: 0s - loss: 0.0033 - mean_absolute_error: 0.0442\n",
      "Epoch 14: loss did not improve from 0.00325\n",
      "36/36 [==============================] - 4s 116ms/step - loss: 0.0033 - mean_absolute_error: 0.0442 - lr: 0.0010\n",
      "Epoch 15/100\n",
      "36/36 [==============================] - ETA: 0s - loss: 0.0032 - mean_absolute_error: 0.0441\n",
      "Epoch 15: loss improved from 0.00325 to 0.00319, saving model to pesos.h5\n",
      "36/36 [==============================] - 4s 121ms/step - loss: 0.0032 - mean_absolute_error: 0.0441 - lr: 0.0010\n",
      "Epoch 16/100\n",
      "36/36 [==============================] - ETA: 0s - loss: 0.0032 - mean_absolute_error: 0.0434\n",
      "Epoch 16: loss improved from 0.00319 to 0.00316, saving model to pesos.h5\n",
      "36/36 [==============================] - 5s 135ms/step - loss: 0.0032 - mean_absolute_error: 0.0434 - lr: 0.0010\n",
      "Epoch 17/100\n",
      "36/36 [==============================] - ETA: 0s - loss: 0.0030 - mean_absolute_error: 0.0418\n",
      "Epoch 17: loss improved from 0.00316 to 0.00298, saving model to pesos.h5\n",
      "36/36 [==============================] - 5s 142ms/step - loss: 0.0030 - mean_absolute_error: 0.0418 - lr: 0.0010\n",
      "Epoch 18/100\n",
      "36/36 [==============================] - ETA: 0s - loss: 0.0032 - mean_absolute_error: 0.0429\n",
      "Epoch 18: loss did not improve from 0.00298\n",
      "36/36 [==============================] - 4s 118ms/step - loss: 0.0032 - mean_absolute_error: 0.0429 - lr: 0.0010\n",
      "Epoch 19/100\n",
      "36/36 [==============================] - ETA: 0s - loss: 0.0027 - mean_absolute_error: 0.0399\n",
      "Epoch 19: loss improved from 0.00298 to 0.00274, saving model to pesos.h5\n",
      "36/36 [==============================] - 4s 122ms/step - loss: 0.0027 - mean_absolute_error: 0.0399 - lr: 0.0010\n",
      "Epoch 20/100\n",
      "36/36 [==============================] - ETA: 0s - loss: 0.0030 - mean_absolute_error: 0.0420\n",
      "Epoch 20: loss did not improve from 0.00274\n",
      "36/36 [==============================] - 4s 124ms/step - loss: 0.0030 - mean_absolute_error: 0.0420 - lr: 0.0010\n",
      "Epoch 21/100\n",
      "36/36 [==============================] - ETA: 0s - loss: 0.0028 - mean_absolute_error: 0.0403\n",
      "Epoch 21: loss did not improve from 0.00274\n",
      "36/36 [==============================] - 4s 123ms/step - loss: 0.0028 - mean_absolute_error: 0.0403 - lr: 0.0010\n",
      "Epoch 22/100\n",
      "36/36 [==============================] - ETA: 0s - loss: 0.0027 - mean_absolute_error: 0.0393\n",
      "Epoch 22: loss improved from 0.00274 to 0.00266, saving model to pesos.h5\n",
      "36/36 [==============================] - 4s 119ms/step - loss: 0.0027 - mean_absolute_error: 0.0393 - lr: 0.0010\n",
      "Epoch 23/100\n",
      "36/36 [==============================] - ETA: 0s - loss: 0.0027 - mean_absolute_error: 0.0396\n",
      "Epoch 23: loss did not improve from 0.00266\n",
      "36/36 [==============================] - 4s 121ms/step - loss: 0.0027 - mean_absolute_error: 0.0396 - lr: 0.0010\n",
      "Epoch 24/100\n",
      "36/36 [==============================] - ETA: 0s - loss: 0.0025 - mean_absolute_error: 0.0380\n",
      "Epoch 24: loss improved from 0.00266 to 0.00249, saving model to pesos.h5\n",
      "36/36 [==============================] - 4s 118ms/step - loss: 0.0025 - mean_absolute_error: 0.0380 - lr: 0.0010\n",
      "Epoch 25/100\n",
      "36/36 [==============================] - ETA: 0s - loss: 0.0026 - mean_absolute_error: 0.0387\n",
      "Epoch 25: loss did not improve from 0.00249\n",
      "36/36 [==============================] - 4s 122ms/step - loss: 0.0026 - mean_absolute_error: 0.0387 - lr: 0.0010\n",
      "Epoch 26/100\n",
      "36/36 [==============================] - ETA: 0s - loss: 0.0025 - mean_absolute_error: 0.0392\n",
      "Epoch 26: loss did not improve from 0.00249\n",
      "36/36 [==============================] - 4s 116ms/step - loss: 0.0025 - mean_absolute_error: 0.0392 - lr: 0.0010\n",
      "Epoch 27/100\n",
      "36/36 [==============================] - ETA: 0s - loss: 0.0026 - mean_absolute_error: 0.0393\n",
      "Epoch 27: loss did not improve from 0.00249\n",
      "36/36 [==============================] - 4s 118ms/step - loss: 0.0026 - mean_absolute_error: 0.0393 - lr: 0.0010\n",
      "Epoch 28/100\n",
      "36/36 [==============================] - ETA: 0s - loss: 0.0025 - mean_absolute_error: 0.0383\n",
      "Epoch 28: loss did not improve from 0.00249\n",
      "36/36 [==============================] - 4s 121ms/step - loss: 0.0025 - mean_absolute_error: 0.0383 - lr: 0.0010\n",
      "Epoch 29/100\n",
      "36/36 [==============================] - ETA: 0s - loss: 0.0024 - mean_absolute_error: 0.0375\n",
      "Epoch 29: loss improved from 0.00249 to 0.00239, saving model to pesos.h5\n",
      "36/36 [==============================] - 4s 117ms/step - loss: 0.0024 - mean_absolute_error: 0.0375 - lr: 0.0010\n",
      "Epoch 30/100\n",
      "36/36 [==============================] - ETA: 0s - loss: 0.0024 - mean_absolute_error: 0.0374\n",
      "Epoch 30: loss did not improve from 0.00239\n",
      "36/36 [==============================] - 4s 117ms/step - loss: 0.0024 - mean_absolute_error: 0.0374 - lr: 0.0010\n",
      "Epoch 31/100\n",
      "36/36 [==============================] - ETA: 0s - loss: 0.0023 - mean_absolute_error: 0.0361\n",
      "Epoch 31: loss improved from 0.00239 to 0.00229, saving model to pesos.h5\n",
      "36/36 [==============================] - 4s 117ms/step - loss: 0.0023 - mean_absolute_error: 0.0361 - lr: 0.0010\n",
      "Epoch 32/100\n",
      "36/36 [==============================] - ETA: 0s - loss: 0.0024 - mean_absolute_error: 0.0380\n",
      "Epoch 32: loss did not improve from 0.00229\n",
      "36/36 [==============================] - 4s 120ms/step - loss: 0.0024 - mean_absolute_error: 0.0380 - lr: 0.0010\n",
      "Epoch 33/100\n",
      "36/36 [==============================] - ETA: 0s - loss: 0.0023 - mean_absolute_error: 0.0370\n",
      "Epoch 33: loss improved from 0.00229 to 0.00228, saving model to pesos.h5\n",
      "36/36 [==============================] - 4s 117ms/step - loss: 0.0023 - mean_absolute_error: 0.0370 - lr: 0.0010\n",
      "Epoch 34/100\n",
      "36/36 [==============================] - ETA: 0s - loss: 0.0024 - mean_absolute_error: 0.0372\n",
      "Epoch 34: loss did not improve from 0.00228\n",
      "36/36 [==============================] - 4s 122ms/step - loss: 0.0024 - mean_absolute_error: 0.0372 - lr: 0.0010\n",
      "Epoch 35/100\n",
      "36/36 [==============================] - ETA: 0s - loss: 0.0022 - mean_absolute_error: 0.0361\n",
      "Epoch 35: loss improved from 0.00228 to 0.00223, saving model to pesos.h5\n",
      "36/36 [==============================] - 4s 119ms/step - loss: 0.0022 - mean_absolute_error: 0.0361 - lr: 0.0010\n",
      "Epoch 36/100\n",
      "36/36 [==============================] - ETA: 0s - loss: 0.0023 - mean_absolute_error: 0.0375\n",
      "Epoch 36: ReduceLROnPlateau reducing learning rate to 0.00020000000949949026.\n",
      "\n",
      "Epoch 36: loss did not improve from 0.00223\n",
      "36/36 [==============================] - 4s 117ms/step - loss: 0.0023 - mean_absolute_error: 0.0375 - lr: 0.0010\n",
      "Epoch 37/100\n",
      "36/36 [==============================] - ETA: 0s - loss: 0.0020 - mean_absolute_error: 0.0339\n",
      "Epoch 37: loss improved from 0.00223 to 0.00203, saving model to pesos.h5\n",
      "36/36 [==============================] - 4s 122ms/step - loss: 0.0020 - mean_absolute_error: 0.0339 - lr: 2.0000e-04\n",
      "Epoch 38/100\n",
      "36/36 [==============================] - ETA: 0s - loss: 0.0020 - mean_absolute_error: 0.0339\n",
      "Epoch 38: loss improved from 0.00203 to 0.00203, saving model to pesos.h5\n",
      "36/36 [==============================] - 4s 118ms/step - loss: 0.0020 - mean_absolute_error: 0.0339 - lr: 2.0000e-04\n",
      "Epoch 39/100\n",
      "36/36 [==============================] - ETA: 0s - loss: 0.0019 - mean_absolute_error: 0.0328\n",
      "Epoch 39: loss improved from 0.00203 to 0.00193, saving model to pesos.h5\n",
      "36/36 [==============================] - 4s 124ms/step - loss: 0.0019 - mean_absolute_error: 0.0328 - lr: 2.0000e-04\n",
      "Epoch 40/100\n",
      "36/36 [==============================] - ETA: 0s - loss: 0.0019 - mean_absolute_error: 0.0334\n",
      "Epoch 40: loss improved from 0.00193 to 0.00192, saving model to pesos.h5\n",
      "36/36 [==============================] - 4s 124ms/step - loss: 0.0019 - mean_absolute_error: 0.0334 - lr: 2.0000e-04\n",
      "Epoch 41/100\n",
      "36/36 [==============================] - ETA: 0s - loss: 0.0019 - mean_absolute_error: 0.0332\n",
      "Epoch 41: loss improved from 0.00192 to 0.00188, saving model to pesos.h5\n",
      "36/36 [==============================] - 5s 125ms/step - loss: 0.0019 - mean_absolute_error: 0.0332 - lr: 2.0000e-04\n",
      "Epoch 42/100\n",
      "36/36 [==============================] - ETA: 0s - loss: 0.0019 - mean_absolute_error: 0.0330\n",
      "Epoch 42: loss did not improve from 0.00188\n",
      "36/36 [==============================] - 4s 122ms/step - loss: 0.0019 - mean_absolute_error: 0.0330 - lr: 2.0000e-04\n",
      "Epoch 43/100\n",
      "36/36 [==============================] - ETA: 0s - loss: 0.0020 - mean_absolute_error: 0.0340\n",
      "Epoch 43: loss did not improve from 0.00188\n",
      "36/36 [==============================] - 4s 125ms/step - loss: 0.0020 - mean_absolute_error: 0.0340 - lr: 2.0000e-04\n",
      "Epoch 44/100\n",
      "36/36 [==============================] - ETA: 0s - loss: 0.0019 - mean_absolute_error: 0.0332\n",
      "Epoch 44: loss did not improve from 0.00188\n",
      "36/36 [==============================] - 4s 123ms/step - loss: 0.0019 - mean_absolute_error: 0.0332 - lr: 2.0000e-04\n",
      "Epoch 45/100\n",
      "36/36 [==============================] - ETA: 0s - loss: 0.0019 - mean_absolute_error: 0.0337\n",
      "Epoch 45: ReduceLROnPlateau reducing learning rate to 4.0000001899898055e-05.\n",
      "\n",
      "Epoch 45: loss did not improve from 0.00188\n",
      "36/36 [==============================] - 4s 122ms/step - loss: 0.0019 - mean_absolute_error: 0.0337 - lr: 2.0000e-04\n",
      "Epoch 46/100\n",
      "36/36 [==============================] - ETA: 0s - loss: 0.0019 - mean_absolute_error: 0.0327\n",
      "Epoch 46: loss did not improve from 0.00188\n",
      "36/36 [==============================] - 4s 121ms/step - loss: 0.0019 - mean_absolute_error: 0.0327 - lr: 4.0000e-05\n",
      "Epoch 47/100\n",
      "36/36 [==============================] - ETA: 0s - loss: 0.0019 - mean_absolute_error: 0.0335\n",
      "Epoch 47: loss did not improve from 0.00188\n",
      "36/36 [==============================] - 4s 121ms/step - loss: 0.0019 - mean_absolute_error: 0.0335 - lr: 4.0000e-05\n",
      "Epoch 48/100\n",
      "36/36 [==============================] - ETA: 0s - loss: 0.0019 - mean_absolute_error: 0.0336\n",
      "Epoch 48: loss did not improve from 0.00188\n",
      "36/36 [==============================] - 4s 120ms/step - loss: 0.0019 - mean_absolute_error: 0.0336 - lr: 4.0000e-05\n",
      "Epoch 49/100\n",
      "36/36 [==============================] - ETA: 0s - loss: 0.0020 - mean_absolute_error: 0.0336\n",
      "Epoch 49: loss did not improve from 0.00188\n",
      "36/36 [==============================] - 4s 121ms/step - loss: 0.0020 - mean_absolute_error: 0.0336 - lr: 4.0000e-05\n",
      "Epoch 50/100\n",
      "36/36 [==============================] - ETA: 0s - loss: 0.0020 - mean_absolute_error: 0.0334\n",
      "Epoch 50: ReduceLROnPlateau reducing learning rate to 8.000000525498762e-06.\n",
      "\n",
      "Epoch 50: loss did not improve from 0.00188\n",
      "36/36 [==============================] - 4s 121ms/step - loss: 0.0020 - mean_absolute_error: 0.0334 - lr: 4.0000e-05\n",
      "Epoch 51/100\n",
      "36/36 [==============================] - ETA: 0s - loss: 0.0020 - mean_absolute_error: 0.0341\n",
      "Epoch 51: loss did not improve from 0.00188\n",
      "36/36 [==============================] - 4s 120ms/step - loss: 0.0020 - mean_absolute_error: 0.0341 - lr: 8.0000e-06\n",
      "Epoch 51: early stopping\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x7ff2b7d1e5d0>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "regressor.fit(previsores, preco_real, epochs=100, batch_size=32, callbacks=[es, rlr, mcp])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_teste = pd.read_csv('/workspaces/learning-machine-learning/udemy/a_z/bolsa_valores/petr4_teste.csv')\n",
    "preco_real_teste = base_teste.iloc[:, 1:2].values\n",
    "frames = [base, base_teste]\n",
    "base_completa = pd.concat(frames)\n",
    "base_completa = base_completa.drop('Date', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "entradas = base_completa[len(base_completa) - len(base_teste) - 90:].values\n",
    "entradas = normalizador.transform(entradas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_teste = []\n",
    "for i in range(90, 112):\n",
    "    x_teste.append(entradas[i-90:i, 0:6])\n",
    "x_teste = np.array(x_teste)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 1s/step\n"
     ]
    }
   ],
   "source": [
    "previsoes = regressor.predict(x_teste)\n",
    "previsoes = normalizador_previsao.inverse_transform(previsoes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "17.46247"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "previsoes.mean()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
