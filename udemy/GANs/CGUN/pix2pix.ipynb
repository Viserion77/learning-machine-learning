{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pathlib\n",
    "import time\n",
    "import datetime\n",
    "from matplotlib import pyplot as plt\n",
    "from IPython import display\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preparação dos dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.random.set_seed(789)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = 'maps' # cityscapes, maps, edges2shoes, edges2handbags, facades, night2day"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arquivo_dataset = \"{}.tar.gz\".format(dataset)\n",
    "url_dataset = \"https://efrosgans.eecs.berkeley.edu/pix2pix/datasets/{}.tar.gz\".format(dataset)\n",
    "print(\"Baixando dataset {}...\".format(dataset))\n",
    "download_zip = tf.keras.utils.get_file(arquivo_dataset, origin=url_dataset, extract=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "download_zip = pathlib.Path(download_zip)\n",
    "caminho = download_zip.parent/dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "caminho"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(caminho.parent.iterdir())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_id = 99 # tf.random.uniform(shape=[], minval=1, maxval=1096, dtype=tf.int64).numpy()\n",
    "amostra = tf.io.read_file(str(caminho/'train/{}.jpg'.format(random_id)))\n",
    "amostra = tf.image.decode_jpeg(amostra)\n",
    "print(amostra.shape)\n",
    "plt.figure(figsize=(10,10))\n",
    "plt.imshow(amostra)\n",
    "plt.title(\"Imagem de exemplo {}\".format(random_id))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Funções para pré-processamento dos dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def carregar_imagem(img_arquivo):\n",
    "  img = tf.io.read_file(img_arquivo)\n",
    "  img = tf.io.decode_jpeg(img)\n",
    "  img = tf.image.resize(img, [256, 512])\n",
    "\n",
    "  largura = tf.shape(img)[1]\n",
    "  largura = largura // 2\n",
    "\n",
    "  imagem_original = img[:, :largura, :]\n",
    "  imagem_transformada = img[:, largura:, :]\n",
    "\n",
    "  imagem_original = tf.cast(imagem_original, tf.float32)\n",
    "  imagem_transformada = tf.cast(imagem_transformada, tf.float32)\n",
    "\n",
    "  return imagem_original, imagem_transformada"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imagem_original, imagem_transformada = carregar_imagem(str(caminho/'train/{}.jpg'.format(random_id)))\n",
    "\n",
    "plt.figure(figsize=(10,10))\n",
    "plt.subplot(121)\n",
    "plt.title('Imagem Original')\n",
    "plt.imshow(imagem_original/255.0)\n",
    "plt.subplot(122)\n",
    "plt.title('Imagem Transformada')\n",
    "plt.imshow(imagem_transformada/255.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "quantidade_treino = tf.data.Dataset.list_files(str(caminho/'train/*.jpg'))\n",
    "quantidade_treino"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "quantidade_treino = len(list(quantidade_treino))\n",
    "quantidade_treino"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "buffer_size = quantidade_treino\n",
    "batch_size = 1\n",
    "img_largura = 256\n",
    "img_altura = 256"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def redimencionar_imagem(imagem_original, imagem_transformada, altura, largura):\n",
    "  imagem_original = tf.image.resize(imagem_original, [altura, largura], method=tf.image.ResizeMethod.NEAREST_NEIGHBOR)\n",
    "  imagem_transformada = tf.image.resize(imagem_transformada, [altura, largura], method=tf.image.ResizeMethod.NEAREST_NEIGHBOR)\n",
    "\n",
    "  return imagem_original, imagem_transformada"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalizar_pixels(imagem_original, imagem_transformada):\n",
    "  imagem_original = (imagem_original / 127.5) - 1\n",
    "  imagem_transformada = (imagem_transformada / 127.5) - 1\n",
    "\n",
    "  return imagem_original, imagem_transformada"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def crop_aleatorio(imagem_original, imagem_transformada):\n",
    "  imagem_empilhada = tf.stack([imagem_original, imagem_transformada], axis=0)\n",
    "  imagem_cortada = tf.image.random_crop(imagem_empilhada, size=[2, img_altura, img_largura, 3])\n",
    "\n",
    "  return imagem_cortada[0], imagem_cortada[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function()\n",
    "def jitter_aleatorio(imagem_original, imagem_transformada):\n",
    "  imagem_original, imagem_transformada = redimencionar_imagem(imagem_original, imagem_transformada, 286, 286)\n",
    "  imagem_original, imagem_transformada = crop_aleatorio(imagem_original, imagem_transformada)\n",
    "\n",
    "  if tf.random.uniform(()) > 0.5:\n",
    "    imagem_original = tf.image.flip_left_right(imagem_original)\n",
    "    imagem_transformada = tf.image.flip_left_right(imagem_transformada)\n",
    "\n",
    "  return imagem_original, imagem_transformada"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,6))\n",
    "for i in range(6):\n",
    "  j_original, j_transformada = jitter_aleatorio(imagem_original, imagem_transformada)\n",
    "  plt.subplot(2,3,i+1)\n",
    "  plt.imshow(j_original/255.0)\n",
    "  plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Carregamento do dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def carrega_img_treinamento(img_arquivo):\n",
    "  imagem_original, imagem_transformada = carregar_imagem(img_arquivo)\n",
    "  imagem_original, imagem_transformada = jitter_aleatorio(imagem_original, imagem_transformada)\n",
    "  imagem_original, imagem_transformada = normalizar_pixels(imagem_original, imagem_transformada)\n",
    "\n",
    "  return imagem_original, imagem_transformada"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def carrega_img_teste(img_arquivo):\n",
    "  imagem_original, imagem_transformada = carregar_imagem(img_arquivo)\n",
    "  imagem_original, imagem_transformada = redimencionar_imagem(imagem_original, imagem_transformada, img_altura, img_largura)\n",
    "  imagem_original, imagem_transformada = normalizar_pixels(imagem_original, imagem_transformada)\n",
    "\n",
    "  return imagem_original, imagem_transformada"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_treino = tf.data.Dataset.list_files(str(caminho/'train/*.jpg'))\n",
    "dataset_treino = dataset_treino.map(carrega_img_treinamento, num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
    "dataset_treino = dataset_treino.shuffle(buffer_size)\n",
    "dataset_treino = dataset_treino.batch(batch_size)\n",
    "dataset_treino"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "  dataset_teste = tf.data.Dataset.list_files(str(caminho/'test/*.jpg'))\n",
    "except tf.errors.InvalidArgumentError:\n",
    "  dataset_teste = tf.data.Dataset.list_files(str(caminho/'val/*.jpg'))\n",
    "\n",
    "dataset_teste = dataset_teste.map(carrega_img_teste)\n",
    "dataset_teste = dataset_teste.batch(batch_size)\n",
    "dataset_teste\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gerador"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode(filters, size, apply_instancenorm=True):\n",
    "  initializer = tf.random_normal_initializer(0.,0.02)\n",
    "\n",
    "  camada = tf.keras.Sequential()\n",
    "  camada.add(tf.keras.layers.Conv2D(filters, size, strides=2, padding='same', kernel_initializer=initializer, use_bias=False))\n",
    "\n",
    "  if apply_instancenorm:\n",
    "    camada.add(tf.keras.layers.BatchNormalization())\n",
    "\n",
    "  camada.add(tf.keras.layers.LeakyReLU())\n",
    "\n",
    "  return camada"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "down_model = encode(64, 4, apply_instancenorm=False)\n",
    "down_resultado = down_model(tf.expand_dims(imagem_original, 0))\n",
    "print(down_resultado.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decode(filters, size, apply_dropout=False):\n",
    "  initializer = tf.random_normal_initializer(0.,0.02)\n",
    "\n",
    "  camada = tf.keras.Sequential()\n",
    "  camada.add(tf.keras.layers.Conv2DTranspose(filters, size, strides=2, padding='same', kernel_initializer=initializer, use_bias=False))\n",
    "\n",
    "  camada.add(tf.keras.layers.BatchNormalization())\n",
    "\n",
    "  if apply_dropout:\n",
    "    camada.add(tf.keras.layers.Dropout(0.5))\n",
    "\n",
    "  camada.add(tf.keras.layers.ReLU())\n",
    "\n",
    "  return camada"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "up_model = decode(64, 4)\n",
    "up_resultado = up_model(down_resultado)\n",
    "print(up_resultado.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gerador_nn():\n",
    "    inputs = tf.keras.layers.Input(shape=[256,256,3])\n",
    "\n",
    "    down_stack = [\n",
    "        encode(64, 4, apply_instancenorm=False), # (bs, 128, 128, 64)\n",
    "        encode(128, 4), # (bs, 64, 64, 128)\n",
    "        encode(256, 4), # (bs, 32, 32, 256)\n",
    "        encode(512, 4), # (bs, 16, 16, 512)\n",
    "        encode(512, 4), # (bs, 8, 8, 512)\n",
    "        encode(512, 4), # (bs, 4, 4, 512)\n",
    "        encode(512, 4), # (bs, 2, 2, 512)\n",
    "        encode(512, 4), # (bs, 1, 1, 512)\n",
    "    ]\n",
    "\n",
    "    up_stack = [\n",
    "        decode(512, 4, apply_dropout=True), # (bs, 2, 2, 1024)\n",
    "        decode(512, 4, apply_dropout=True), # (bs, 4, 4, 1024)\n",
    "        decode(512, 4, apply_dropout=True), # (bs, 8, 8, 1024)\n",
    "        decode(512, 4), # (bs, 16, 16, 1024)\n",
    "        decode(256, 4), # (bs, 32, 32, 512)\n",
    "        decode(128, 4), # (bs, 64, 64, 256)\n",
    "        decode(64, 4), # (bs, 128, 128, 128)\n",
    "    ]\n",
    "\n",
    "    canais_saida = 3\n",
    "    initializer = tf.random_normal_initializer(0.,0.02)\n",
    "    ultima_camada = tf.keras.layers.Conv2DTranspose(canais_saida, 4, strides=2, padding='same', kernel_initializer=initializer, activation='tanh') # (bs, 256, 256, 3)\n",
    "\n",
    "    x = inputs\n",
    "\n",
    "    skips = []\n",
    "    for down in down_stack:\n",
    "        x = down(x)\n",
    "        skips.append(x)\n",
    "\n",
    "    skips = reversed(skips[:-1])\n",
    "\n",
    "    for up, skip in zip(up_stack, skips):\n",
    "        x = up(x)\n",
    "        x = tf.keras.layers.Concatenate()([x, skip])\n",
    "\n",
    "    x = ultima_camada(x)\n",
    "\n",
    "    return tf.keras.Model(inputs=inputs, outputs=x)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gerador = gerador_nn()\n",
    "tf.keras.utils.plot_model(gerador, show_shapes=True, dpi=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g_saida = gerador(imagem_original[tf.newaxis,...], training=False)\n",
    "plt.imshow(g_saida[0,...])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = 2e-4\n",
    "beta_1, beta_2 = 0.5, 0.999\n",
    "lambda_ciclo = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = tf.keras.losses.BinaryCrossentropy(from_logits=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_gerador(discriminador_fake_output, gerador_output, target):\n",
    "  gan_loss = loss(tf.ones_like(discriminador_fake_output), discriminador_fake_output)\n",
    "\n",
    "  l1_loss = tf.reduce_mean(tf.abs(target - gerador_output))\n",
    "\n",
    "  total_loss = gan_loss + (lambda_ciclo * l1_loss)\n",
    "\n",
    "  return total_loss, gan_loss, l1_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Discriminador"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def discriminador():\n",
    "  initializer = tf.random_normal_initializer(0.,0.02)\n",
    "\n",
    "  original = tf.keras.layers.Input(shape=[256,256,3], name='img_original')\n",
    "  transformada = tf.keras.layers.Input(shape=[256,256,3], name='img_transformada')\n",
    "\n",
    "  entrada = tf.keras.layers.concatenate([original, transformada]) # (bs, 256, 256, channels*2)\n",
    "\n",
    "  down1 = encode(64, 4, False)(entrada) # (bs, 128, 128, 64)\n",
    "  down2 = encode(128, 4)(down1) # (bs, 64, 64, 128)\n",
    "  down3 = encode(256, 4)(down2) # (bs, 32, 32, 256)\n",
    "\n",
    "  zero_pad1 = tf.keras.layers.ZeroPadding2D()(down3) # (bs, 34, 34, 256)\n",
    "  conv = tf.keras.layers.Conv2D(512, 4, strides=1, kernel_initializer=initializer, use_bias=False)(zero_pad1) # (bs, 31, 31, 512)\n",
    "\n",
    "  batchnorm1 = tf.keras.layers.BatchNormalization()(conv)\n",
    "\n",
    "  leaky_relu = tf.keras.layers.LeakyReLU()(batchnorm1)\n",
    "\n",
    "  zero_pad2 = tf.keras.layers.ZeroPadding2D()(leaky_relu) # (bs, 33, 33, 512)\n",
    "\n",
    "  ultima_camada = tf.keras.layers.Conv2D(1, 4, strides=1, kernel_initializer=initializer)(zero_pad2) # (bs, 30, 30, 1)\n",
    "\n",
    "  return tf.keras.Model(inputs=[original, transformada], outputs=ultima_camada)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "discriminador = discriminador()\n",
    "tf.keras.utils.plot_model(discriminador, show_shapes=True, dpi=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d_saida = discriminador([imagem_original[tf.newaxis,...], g_saida], training=False)\n",
    "plt.imshow(d_saida[0,...,-1], vmin=-20, vmax=20, cmap='RdBu_r')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Perda do discriminador"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_discriminador(discriminador_real_output, discriminador_fake_output):\n",
    "  real_loss = loss(tf.ones_like(discriminador_real_output), discriminador_real_output)\n",
    "\n",
    "  fake_loss = loss(tf.zeros_like(discriminador_fake_output), discriminador_fake_output)\n",
    "\n",
    "  total_loss = real_loss + fake_loss\n",
    "\n",
    "  return total_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Otimizadores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizador_gerador = tf.keras.optimizers.Adam(lr, beta_1, beta_2)\n",
    "optimizador_discriminador = tf.keras.optimizers.Adam(lr, beta_1, beta_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# checkpoints (Object-based saving)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_dir = 'pix2pix/treinamento_checkpoints'\n",
    "checkpoint_prefix = os.path.join(checkpoint_dir, \"ckpt\")\n",
    "checkpoint = tf.train.Checkpoint(generator_optimizer=optimizador_gerador,\n",
    "                                  discriminador_optimizer=optimizador_discriminador,\n",
    "                                  generator=gerador,\n",
    "                                  discriminador=discriminador)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Geração de imagens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gerar_imagens(modelo, teste_entrada, real, etapa = None):\n",
    "  pred = modelo(teste_entrada, training=True)\n",
    "  plt.figure(figsize=(12,8))\n",
    "\n",
    "  display_list = [teste_entrada[0], real[0], pred[0]]\n",
    "  titulo = ['Imagem de entrada', 'Real (ground truth)', 'Imagem gerada (Fake)']\n",
    "\n",
    "  for i in range(3):\n",
    "    plt.subplot(1,3,i+1)\n",
    "    plt.title(titulo[i])\n",
    "    plt.imshow(display_list[i] * 0.5 + 0.5)\n",
    "    plt.axis('off')\n",
    "  if etapa != None:\n",
    "    plt.savefig('pix2pix/img_{}.png'.format(etapa), bbox_inches='tight')\n",
    "  plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for exemplo_input, exemplo_target in dataset_teste.take(7):\n",
    "  gerar_imagens(gerador, exemplo_input, exemplo_target)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Treinamento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "caminho_log = 'pix2pix/logs/'\n",
    "metricas = tf.summary.create_file_writer(caminho_log + \"fit/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def etapa_treinamento(img_entrada, real, etapa):\n",
    "  with tf.GradientTape() as gen_tape, tf.GradientTape() as disc_tape:\n",
    "    gerador_output = gerador(img_entrada, training=True)\n",
    "\n",
    "    discriminador_real_output = discriminador([img_entrada, real], training=True)\n",
    "    discriminador_fake_output = discriminador([img_entrada, gerador_output], training=True)\n",
    "\n",
    "    gen_total_loss, gen_gan_loss, gen_l1_loss = loss_gerador(discriminador_fake_output, gerador_output, real)\n",
    "    disc_loss = loss_discriminador(discriminador_real_output, discriminador_fake_output)\n",
    "\n",
    "  gerador_gradientes = gen_tape.gradient(gen_total_loss, gerador.trainable_variables)\n",
    "  discriminador_gradientes = disc_tape.gradient(disc_loss, discriminador.trainable_variables)\n",
    "\n",
    "  optimizador_gerador.apply_gradients(zip(gerador_gradientes, gerador.trainable_variables))\n",
    "  optimizador_discriminador.apply_gradients(zip(discriminador_gradientes, discriminador.trainable_variables))\n",
    "\n",
    "  with metricas.as_default():\n",
    "    tf.summary.scalar('gen_total_loss', gen_total_loss, step=etapa//1000)\n",
    "    tf.summary.scalar('gen_gan_loss', gen_gan_loss, step=etapa//1000)\n",
    "    tf.summary.scalar('gen_l1_loss', gen_l1_loss, step=etapa//1000)\n",
    "    tf.summary.scalar('disc_loss', disc_loss, step=etapa//1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def treinar(base_treinamento, base_teste, etapas):\n",
    "  exemplo_input, exemplo_target = next(iter(base_teste.take(1)))\n",
    "  inicio = time.time()\n",
    "\n",
    "  for etapa, (img_entrada, real) in base_treinamento.repeat().take(etapas).enumerate():\n",
    "    if etapa % 1000 == 0:\n",
    "      display.clear_output(wait=True)\n",
    "\n",
    "      if (etapa != 0):\n",
    "        tempo = time.time() - inicio\n",
    "        print ('Tempo decorrido: {} segundo'.format(tempo))\n",
    "\n",
    "      inicio = time.time()\n",
    "\n",
    "      gerar_imagens(gerador, exemplo_input, exemplo_target, etapa)\n",
    "      print ('Etapa: {}'.format(etapa))\n",
    "\n",
    "    etapa_treinamento(img_entrada, real, etapa)\n",
    "    if (etapa + 1) % 10 == 0:\n",
    "      print ('.', end='', flush=True)\n",
    "    if (etapa + 1) % 5000 == 0:\n",
    "      checkpoint.save(file_prefix = checkpoint_prefix)\n",
    "      gerador.set_weights(gerador.get_weights())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext tensorboard\n",
    "%tensorboard --logdir {caminho_log}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "treinar(dataset_treino, dataset_teste, etapas=5000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gerador.save_weights('pix2pix/gerador.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Restaurando o último checkpoint para testes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.train.latest_checkpoint(checkpoint_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint.restore(tf.train.latest_checkpoint(checkpoint_dir))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelo_pre_treinado = gerador_nn()\n",
    "modelo_pre_treinado.load_weights('pix2pix/gerador.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for satelite, mapa in dataset_teste.take(5):\n",
    "  gerar_imagens(modelo_pre_treinado, satelite, mapa)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
